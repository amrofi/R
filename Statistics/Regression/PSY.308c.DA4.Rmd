---
title: "PSY 308c DA4 Regression Diagnostics"
author: "Daniel Pinedo"
date: "March 5, 2019"
output: word_document
---
  
  <!-- LEAVE THIS HERE, DO NOT PUT ANY CODE ABOVE IT -->
```{r, echo=FALSE, results=FALSE, message=FALSE, cache=FALSE}
library(knitr); opts_chunk$set(error=TRUE, cache=FALSE)
```


*Prompt*  

You are hired by Sylvan Learning Center to investigate what best **predicts intelligence**. They want to incorporate this information into their ACT prep classes. The company hires you to complete a comprehensive literature review, reserach proposal, and expect a polished report back to them at their end-of-year meeting.

According to the **literature review**, a number of variables were related to intelligence. Among these variables included: **working memory**, **processing speed**, and **vocabulary**, as important predictors of intelligence. This being the case, you are given access to their database of collected information regarding student performance and a variety other measures. Please investigate and report back to Sylvan regarding the **most appropriate explantory model predicting intelligence for their sample of students**.

*Measures:* 
[all variables are on a scale of 0 to 10 unless otherwise noted]
**intell**: measure of intelligence (Raven's Progessive Matrices)
**wm**: measure of working memory (Letter Number Sequencing)
**process**: measure of processing speed (Letter Comparison)
**vocab**: measure of vocabulary (Peabody Picture Vocabulary Test)

*Demographics:*
**Age**: in years (open-text input).
**Sex**: self-reported.
**Race**: self-reported (NR = not reported).
  
Use the data in the file to investigate the relationships among these four measures and to predict intelligence from working memory, processing speed, and vocabulary. *Additionally, please be sure to incorporate learned procedures and data analysis techniques as appropriate.*
  
    
```{r echo = FALSE, message = FALSE}
dat <- read.csv('https://www.dropbox.com/s/v69ox13u9xr28r0/PSY.308c.DA4.csv?dl=1') #read csv file into data frame
```

```{r echo = FALSE, message = FALSE}
library(pacman) #Package used to load all packages using p_load(); will install missing packages
p_load(psych, jmv, car, Hmisc, MVN, mice, VIM, ggplot2, ggeffects)
# psych is used for multivariate analysis
# jmv is used for making outputs nice and here assists with hierarchical regression
# car is used for ncvTest()
# Hmisc is used for imputing values in impute() --> not used in this analysis
# MVN is used for multivariate outlier detection
# mice is used for imputing values in md.pattern()
# VIM is used for visualizing imputed values
# ggplot2 adds cool plots
# ggefects is for ggpredict() and ggtitle()
```

**Initial Data Diagnosis**
```{r}
# Descriptives to get an overall view of data
desc <- descriptives(data = dat, 
                        vars = c('intell', 'wm', 'process', 'vocab', 'age', 'Sex', 'Race'),
                        sd = TRUE, 
                        range = TRUE,
                        skew = TRUE, 
                        kurt = TRUE,
                        freq = TRUE) # for categorical variables
desc

corr.test(dat[2:5]) # Prerequisite: outcome and predictor variables are measured on the continuous level

#MISSING DATA --> Different N's and the line that indicates missing items indicates missing cases 
#Running dim(dat) indicates 148 rows/observations
#Options: (1) delete list-wise (2) impute 
```

*Regression Diagnostics*
1. Missing Data
2. Univariate a. Normality, b. Linearity and c. Outliers
3. Multivariate a. Normality and b.Outliers
4. Heteroscedsticity
5. Multi-collinearity
6. Linearity between outcome and predictor(s)


**1. Missing Data**
```{r}
#check the pattern of missing data
dat[rowSums(is.na(dat)) > 0,]

md.pattern(dat)

mice_plot <-aggr(dat, 
                 col=c('purple', 'orange'), 
                 numbers = TRUE, 
                 sortVars = TRUE, 
                 labels = names(dat), 
                 cex.axis = .7, 
                 gap = 3, 
                 ylab = c("Missing data", "Pattern"))

#orange bar chart is percentage missing from each variable --> no greater than 2.5% here
#purple and orange(missing) chart shows pattern of missing data --> no pattern here
```

```{r}
# Option 1: Listwise deletion of missing data. New dataset is named "dat.no.NA"
dat.no.NA <- na.omit(dat)

#check descriptives again

desc_listwise <- descriptives(data = dat.no.NA, 
                              vars = c('intell', 'wm', 'process', 'vocab', 'age', 'Sex', 'Race'),
                              sd = TRUE, 
                              range = TRUE,
                              skew = TRUE, 
                              kurt = TRUE,
                              freq = TRUE) # for categorical variables
desc_listwise

#N is all 136 (from 148) now and no missing data --> 12 observations removed (8%)
#Option 2: impute missing values. See Regression_Diagnostics.Rmd for how-to
#Big data set, can drop a few cases --> so going to continue on with more conservative "delete list-wise" data set
```

**2a. Univariate Normality**
```{r}
#ASSUMPTION: Normal Distribution for continuous variables X and Y (Intelligence) [i.e. histogram, skew +-3, kurtosis +-10]

desc_listwise.hist <- descriptives(data = dat.no.NA, 
                              vars = c('intell', 'wm', 'process', 'vocab'),
                              sd = TRUE,
                              range = TRUE,
                              skew = TRUE, 
                              kurt = TRUE,
                              hist = TRUE) # for visual inspection
desc_listwise.hist

# Histogram for Intelligence (intell) is normal
    # Histogram for Working Memory (wm) is normal
    # Histogram for Processing Speed (process) is normal
    # Histogram for Vocabulary (vocab) is normal
    # Skewness - ALL PASS
    # Kurtosis - ALL PASS  

#Visual inspection indicates however that there may be outliers
  #Intelligence (intell) in negative tail
  #Working Memory (wm) in negative tail
  #Processing Speed  (process) has no outliers
  #Vocabulary (vocab) in Negative Tail
```

**2b. Univariate Linearity**
```{r}
# Scatterplots [Assumption 2 and 3a]
plot(dat.no.NA$wm, dat.no.NA$intell, abline(lm(dat.no.NA$intell ~ dat.no.NA$wm)))
plot(dat.no.NA$process, dat.no.NA$intell, abline(lm(dat.no.NA$intell ~ dat.no.NA$process)))
plot(dat.no.NA$vocab, dat.no.NA$intell, abline(lm(dat.no.NA$intell ~ dat.no.NA$vocab)))

#visual inspection indicates a likely linear relationship and is consistent with visual inspection of histograms (step 2a) for outliers
```

**2c. Univariate Outliers**
```{r}
#Identify outliers
#scale() converts to z scores - "3" refers to standard deviations
dat.no.NA[abs(scale(dat.no.NA$intell)) > 3, ]
dat.no.NA[abs(scale(dat.no.NA$wm)) > 3, ]
dat.no.NA[abs(scale(dat.no.NA$process)) > 3, ]
dat.no.NA[abs(scale(dat.no.NA$vocab)) > 3, ]

#Intelligence (intell) has 3 univariate outliers
#Working Memory (wm) has 1 univariate outliers
#Processing Speed  (process) has 0 univariate outliers
#Vocabulary (vocab) has 1 univariate outlier
#There are a total of 3 independent observations that contain outliers
```

```{r}
#Remove outliers - order here matters
#Order to remove matters - look up for loop for this ugly code
dat.no.uni <- dat.no.NA[!abs(scale(dat.no.NA$intell)) > 3, ]

#Removed 3 cases that were outside +/-3 SD's for the variables

#Check descriptives for N and assumption of univariate normality in histograms, skew, and kurtosis
desc.no.uni <- descriptives(data = dat.no.uni, 
                             vars = c('intell', 'wm', 'process', 'vocab'),
                              sd = TRUE,
                              range = TRUE,
                              skew = TRUE, 
                              kurt = TRUE,
                              hist = TRUE) # for visual inspection
desc.no.uni

# Histogram for Intelligence (intell) is normal
    # Histogram for Working Memory (wm) is normal
    # Histogram for Processing Speed (process) is normal
    # Histogram for Vocabulary (vocab) is normal
    # Skewness - ALL PASS
    # Kurtosis - ALL PASS 

# N is now 133 after removing 3 independent cases with univariate outliers, 
    #was 136 after removing 8 observations with missing parameters
    #was 148 originally

# everything is now within range of normal distribution
# if this did not fix the problem, square root or log transform may help - See Regression_Diagnostics.Rmd for how-to
```

**3a. Multivariate Normality**
```{r}

#look at residuals and the Q-Q plot
#Observe Leverage (Mahalanobis' Distance) + Discrepancy (= Influence; Cook's Distance)

model.multi_norm <- linReg(data = dat.no.uni, 
                dep = 'intell', 
                covs = c('wm', 'process', 'vocab'),
                blocks = list(c('wm', 'process', 'vocab')), 
                modelTest = TRUE, 
                r2Adj = TRUE, 
                stdEst = TRUE, 
                ciStdEst = TRUE,
                qqPlot = TRUE,  ##QQ plot
                resPlots = TRUE) ##residuals plot 

model.multi_norm

#Alternate not using jvm library
#model <- lm(Amount ~ Belief + Need, data = dat.no.uni)
#plot(model)

#inspection of plots of predictors vs residuals indicates likely multivariate normality, but possible heteroscadasticity
#inspection of theoretical quantiles vs standardized residuals indicates a possible problem with multivariate distance and leverage
#as such, Cook's distance - a measure of influence - will be used to test for multivariate normality
#for Mahalanobis' Distance (leverage only), see Regression_Diagnostics.Rmd for how-to
```

**3b. Multivariate Outliers**
```{r}
#Check and remove multivariate outliers based on Cook's distance (CD)
#CD = Influence = Leverage + Discrepancy (Discrepancy = how much an observation deviates from the overall pattern of the model)

#create model
model.cook <- lm(dat.no.uni$intell ~ dat.no.uni$wm + dat.no.uni$process + dat.no.uni$vocab)
model.cook
summary(model.cook)

#find cook's distance for that model
dat.no.uni$cook <- cooks.distance(model.cook)

#create the cutoff [> 4/N]
cook.cutoff <- 4/nrow(dat.no.uni) 
cook.cutoff

# 4/133 --> cutoff = .03

#plot it out
plot(model.cook, which = 4, cook.levels = cook.cutoff)

#Add a cutoff line
abline(h = cook.cutoff, lty = 2) 

#Show and remove all outliers above your cutoff line

dat.no.uni[(dat.no.uni$cook) > cook.cutoff,]
dat.final <- dat.no.uni[!(dat.no.uni$cook) > cook.cutoff,]

#N is now 127 after removing 6 multivariate outlier observations
    #was 133 after removing 3 univariate outlier obervations, 
    #was 136 after removing 8 observations with missing parameters
    #was 148 originally (total 21 observations removed from orginal dataset - 14%)

```

**4. Heteroscedasticity**
```{r}

#Breusch-Pagan test 
#H0 = no change in variance across residuals.
model.breusch_pagan <- lm(dat.final$intell ~ dat.final$wm + dat.final$process + dat.final$vocab)
ncvTest(model.breusch_pagan)

#not significant = homoscedastic
#If violated use Box-cox transformation [boxcox(model)] in library MASS

```

**5. Multi-collinearity**
```{r}

#Tolerance = 1 - R squared --> for our purpose < .4 is bad
#VIF = 1/Tolerance ---> for our purpose > 2.5 is bad
#Small VIF values (or higher Tolerance values) indicates low correlation among variables under ideal conditions

#Multicollinearity occurs when two or more predictors in the model are correlated and provide redundant information about the response. Multicollinearity is measured by variance inflation factors (VIF) and tolerance. If VIF value exceeds 4.0, or tolerance less than 0.2 then there is a problem with multicollinearity according to Hair et al. (2010).

model.wm_process_vocab <- linReg(data = dat.final, 
                 dep = 'intell', 
                 cov = c('wm', 'process', 'vocab'),
                 blocks = list(c('wm', 'process', 'vocab')), 
                 modelTest = TRUE,
                 r2Adj = TRUE,
                 stdEst = TRUE,
                 ciStdEst = TRUE, 
                 collin = TRUE) #this line does the thing
model.wm_process_vocab

#Tolerance for all variables indicates low/no multicollinearity
```

*Data Analysis*
1. Descriptive Statistics
2. Correlations
3. Center Data (if useful)
4. Simple Regression
5. Hierarchical Model Comparison
6. Visualization

**1. Descriptive Statistics**
```{r}

#Prerequisite: predictors and outcome all measured on continuous level
#Assumptions:
  #1. Normal Distribution for X and Y (Product) [i.e. histogram, skew +-3, kurtosis +-10]
    # Histograms observed are normal
    # Skewness - ALL PASS
    # Kurtosis - ALL PASS
    # Observations with missing parameters were removed (see Diagnostics)
    # univariate outliers were removed (see Diagnostics)
    # multivariate outliers were removed (see Diagnostics)
  
  #2. Linear Relationship beween X and Y
    # Visual inspection of scatterplot and prediction model line in Diagnostics 2b. indicate a linear relationship
  #3. Homoscedasticity - OK (see Diagnostics)
  #4. Multicollearity -diagnostics completed - OK (see Diagnostics)

#N is now 127 after removing 6 multivariate outlier observations
    #was 133 after removing 3 univariate outlier obervations, 
    #was 136 after removing 8 observations with missing parameters
    #was 148 originally (total 21 observations removed from orginal dataset - 14%)

desc.final <- descriptives(data = dat.final, 
                     vars = c('intell', 'wm', 'process', 'vocab', 'age', 'Sex', 'Race'), 
                     hist = TRUE, 
                     sd = TRUE, 
                     range = TRUE, 
                     skew = TRUE, 
                     kurt = TRUE,
                     freq = TRUE)
desc.final
```
**2. Correlations**
```{r}
# Correlations of predictor and outcome variables
cortable <- corrMatrix(data = dat.final, 
                       vars = c('intell', 'wm', 'process', 'vocab'), 
                       flag = TRUE)
cortable

```

**3. Center data (if useful)**
```{r}
# Center only predictor variables
# c = x - M
# Centering only changes the intercept for regression equation
  # Centering means, on average (instead of zero) across all predictor variables Y intercept is [coefficient for X units]
# Center predictors wm, process, vocab
dat.final$wm.centered <- dat.final$wm - mean(dat.final$wm)
dat.final$process.centered <- dat.final$process - mean(dat.final$process)
dat.final$vocab.centered <- dat.final$vocab - mean(dat.final$vocab)

#NOT USEFUL - We will not center data for models of these predictors, as negative predicted values would not make much sense for a test with no possible score below zero.
```

**4. Simple Regression**
```{r}
# Simple regression
# R = correlation between observed scores and predicted scores
# R squared = percentage of variance explained
# t = Estimate / SE
# df1 = k = number of predictors
# df2 = N - k - 1 [k is number of predictors]
# H0: B0 = 0; H0; R squared = 0

model.wm <- linReg(data = dat.final,
                 dep = 'intell', 
                 covs = c('wm'),
                 blocks = list('wm'), 
                 modelTest = TRUE, 
                 stdEst = TRUE, 
                 ci = TRUE)
model.wm #1 fit

model.process <- linReg(data = dat.final,
                 dep = 'intell',
                 covs = c('process'),
                 blocks = list('process'), 
                 modelTest = TRUE, 
                 stdEst = TRUE, 
                 ci = TRUE)
model.process #2 fit

model.vocab <- linReg(data = dat.final, 
                 dep = 'intell',
                 covs = c('vocab'),
                 blocks = list('vocab'), 
                 modelTest = TRUE, 
                 stdEst = TRUE, 
                 ci = TRUE)
model.vocab #3 fit
```

**5. Hierarchical Model Comparison**
```{r}
# Model comparison
# H0 = delta of R squared = 0
compare <- linReg(data = dat.final, 
                  dep = 'intell', 
                  covs = c('wm', 'process', 'vocab'),
                  blocks = list(
                            list('wm'),
                            list('vocab', 'process')), 
                  modelTest = TRUE, 
                  stdEst = TRUE, 
                  ci = TRUE)
compare

#simple regression model with wm compared with nested movel adding vocab + process
#simple model is best fit overall

``` 

**6. Visualization**
```{r}
# plotting a simple regression model based on: 
  # Model 1: intell ~ wm.centered 

# create linear model
model.final <- lm(intell ~ wm, data = dat.final)
summary(model.final)
model_p <- ggpredict(model.final, full.data = TRUE, pretty = TRUE) #for multiple regression, add terms = c("v1"", "v2", "vn")

# plot predicted line - for multiple regression, change to aes(x, predicted)
plot <- ggplot(model.final, aes(y = intell, x = wm)) +
      geom_smooth(method = "lm", se = TRUE, fullrange = TRUE) + scale_x_continuous(limits = c(5, 10.2)) + 
      scale_y_continuous(limits = c(0, 9)) + xlab("Working Memory Score") + ggtitle("Plot of Model of Working Memory Predicting Intelligence") + ylab("Intelligence") + geom_point() + theme_minimal()

plot
```