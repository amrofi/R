knitr::opts_chunk$set(echo = TRUE)
#Load libraries
library(psych)
library(car)
library(lsr)
library(jmv)
library(ggeffects)
library(ggplot2)
dat <- read.csv("https://www.dropbox.com/s/w3wl461s45t1yia/PSY.308c.DA3.csv?dl=1")
View(dat)
# Prerequisitites
# 1. Variables are measured on the continuous level
# Assumptions
# 1. Normal Distribution for X and Y (Product) [i.e. histogram, skew +-3, kurtosis +-10]
# Histogram for Income appears
# Histogram for Illitaracy appears
# Histogram for Safety appears symmetric and bimodal
# Histogram for Success appears symmetric and bimodal
# Skewness -
# Kurtosis -
# 2. Linear Relationship beween X and Y
# Visual inspection of scatterplot and prediction model line indicate ...
# 3. Homoscedasticity
# a. Visual inspection of scatterplots indicate:
#
# b. non-constant variance test - H0 = TRUE (PASS)
# 4. [Examine residuals (e = Y - Y~predicted~) to understand 2 and 3 mathematically]
# Descriptives [Assumption 1]
desc <- descriptives(data = dat,
vars = c('Income', 'Illiteracy', 'Safety', 'Success'),
hist = TRUE,
sd = TRUE,
range = TRUE,
skew = TRUE,
kurt = TRUE)
desc
# Prerequisitites
# 1. Variables are measured on the continuous level
# Assumptions
# 1. Normal Distribution for X and Y (Product) [i.e. histogram, skew +-3, kurtosis +-10]
# Histogram for Income appears
# Histogram for Illitaracy appears
# Histogram for Safety appears symmetric and bimodal
# Histogram for Success appears symmetric and bimodal
# Skewness -
# Kurtosis -
# 2. Linear Relationship beween X and Y
# Visual inspection of scatterplot and prediction model line indicate ...
# 3. Homoscedasticity
# a. Visual inspection of scatterplots indicate:
#
# b. non-constant variance test - H0 = TRUE (PASS)
# 4. [Examine residuals (e = Y - Y~predicted~) to understand 2 and 3 mathematically]
# Descriptives [Assumption 1]
desc <- descriptives(data = dat,
vars = c('Income', 'Illiteracy', 'Safety', 'Success'),
hist = TRUE,
sd = TRUE,
range = TRUE,
skew = TRUE,
kurt = TRUE)
desc
# Scatterplots [Assumption 2 and 3a]
plot(dat$Income, dat$Success, abline(lm(dat$Success ~ dat$Income)))
plot(dat$Illiteracy, dat$Success, abline(lm(dat$Success ~ dat$Illiteracy)))
plot(dat$Safety, dat$Success, abline(lm(dat$Success ~ dat$Safety)))
# Homoscedasticity [Assumption 3b]
# non-constant variance Chi-squared test [Chi-squared (df) = ##.##, p = .###]
# H0 = homoscedastic - TRUE
# Ha = heteroscedastic
ncvTest(lm(Success ~ Income + Illiteracy + Safety, data = dat))
# Correlation
cortable <- corrMatrix(data = dat,
vars = c('Income', 'Illiteracy', 'Safety', 'Success'),
flag = TRUE)
cortable
# c = x - M
# Centering only quantitatively changes the intercept for regression equation
# Center Income, Illiteracy, Safety
dat$Income.c <- dat$Income - mean(dat$Income)
dat$Illiteracy.c <- dat$Illiteracy - mean(dat$Illiteracy)
dat$Safety.c <- dat$Safety - mean(dat$Safety)
# Simple regression
# R = correlation between observed scores and predicted scores
# R squared = percentage of variance explained
# t = Estimate / SE
# df = N - k - 1 [k is number of predictors]
# H0: B0 = 0; H0; R squared = 0
model1 <- linReg(data = dat,
dep = 'Success',
covs = c('Income.c'),
blocks = list('Income.c'),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
model1
model2 <- linReg(data = dat,
dep = 'Success',
covs = c('Illiteracy.c'),
blocks = list('Illiteracy.c'),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
model2
model3 <- linReg(data = dat,
dep = 'Success',
covs = c('Safety.c'),
blocks = list('Safety.c'),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
model3
# Model comparison
# D1 is predicted difference between D1 (Graduated later) and reference group (Did not graduate) for a 1 unit change in Y (Success)
# D2 is predicted difference between D2 (Graduated normal) and reference group (did not graduate) for 1 unit change in Y (Success)
model4 <- linReg(data = dat,
dep = 'Success', #outcome
covs = c('D1', 'D2'), #predictors
blocks = list(c('D1', 'D2')), #order matters here if separate blocks of variables are provided
modelTest = TRUE,
stdEst = TRUE,
ciStdEst = TRUE,
r2Adj = TRUE)
model4
# Model comparison
# H0 = delta of R squared = 0
compare5 <- linReg(data = dat,
dep = 'Success',
covs = c('Income.c', 'Illiteracy.c'),
blocks = list(
list('Income.c'),
list('Illiteracy.c')),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
compare5
# Model comparison
# H0 = delta of R squared = 0
compare5 <- linReg(data = dat,
dep = 'Success',
covs = c('Income.c', 'Illiteracy.c'),
blocks = list(
list('Income.c'),
list('Illiteracy.c')),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
compare5
# Model comparison
# H0 = delta of R squared = 0
compare5 <- linReg(data = dat,
dep = 'Success',
covs = c('Income.c', 'Illiteracy.c', 'Safety.c'),
blocks = list(
list('Income.c', 'Illiteracy.c'),
list('Safety.c')),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
compare5
# Model comparison
# H0 = delta of R squared = 0
compare <- linReg(data = dat,
dep = 'Success',
covs = c('Income.c', 'Safety.c'),
blocks = list(
list('Income.c'),
list('Safety.c')),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
compare
# Model comparison
# H0 = delta of R squared = 0
# D1 is predicted difference between D1 (Graduated later) and reference group (Did not graduate) for a 1 unit change in Y (Success)
# D2 is predicted difference between D2 (Graduated normal) and reference group (did not graduate) for 1 unit change in Y (Success)
compare5 <- linReg(data = dat,
dep = 'Success',
covs = c('Income.c', 'Illiteracy.c', 'D1', 'D2'),
blocks = list(
list('Income.c', 'Illiteracy.c'),
list('D1', 'D2')),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
compare5
# Model comparison
# H0 = delta of R squared = 0
# D1 is predicted difference between D1 (Graduated later) and reference group (Did not graduate) for a 1 unit change in Y (Success)
# D2 is predicted difference between D2 (Graduated normal) and reference group (did not graduate) for 1 unit change in Y (Success)
compare <- linReg(data = dat,
dep = 'Success',
covs = c('Income.c', 'D1', 'D2'),
blocks = list(
list('Income.c'),
list('D1', 'D2')),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
compare
# Model comparison
# H0 = delta of R squared = 0
compare6 <- linReg(data = dat,
dep = 'Success',
covs = c('Income.c', 'Safety.c'),
blocks = list(
list('Income.c'),
list('Safety.c')),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
compare6
# plotting a multiple regression model based on:
# Model 5: Success.c ~ Income.c + Illiteracy.c [centered predictors]
# create predicted values from predictors and save in object
model5<- lm(Success ~ Income.C + Illiteracy.C, data = dat)
# plotting a multiple regression model based on:
# Model 5: Success.c ~ Income.c + Illiteracy.c [centered predictors]
# create predicted values from predictors and save in object
model5 <- lm(Success ~ Income.C + Illiteracy.C, data = dat)
# plotting a multiple regression model based on:
# Model 5: Success.c ~ Income.c + Illiteracy.c [centered predictors]
# create predicted values from predictors and save in object
model5 <- lm(Success ~ Income.C + Illiteracy.C, data = dat)
# plotting a multiple regression model based on:
# Model 5: Success.c ~ Income.c + Illiteracy.c [centered predictors]
# create predicted values from predictors and save in object
model5 <- lm(Success ~ Income + Illiteracy, data = dat)
summary(model5)
model_p <- ggpredict(modelA.2, terms = c('Income.C', 'Illiteracy.C'), full.data = TRUE,  pretty = FALSE)
# plotting a multiple regression model based on:
# Model 5: Success.c ~ Income.c + Illiteracy.c [centered predictors]
# create predicted values from predictors and save in object
model5 <- lm(Success ~ Income.c + Illiteracy.c, data = dat)
summary(model5)
model_p <- ggpredict(modelA.2, terms = c('Income.c', 'Illiteracy.c'), full.data = TRUE,  pretty = FALSE)
# plotting a multiple regression model based on:
# Model 5: Success.c ~ Income.c + Illiteracy.c [centered predictors]
# create predicted values from predictors and save in object
model5 <- lm(Success ~ Income.c + Illiteracy.c, data = dat)
summary(model5)
model_p <- ggpredict(model5, terms = c('Income.c', 'Illiteracy.c'), full.data = TRUE,  pretty = FALSE)
# plot predicted line
plot <- ggplot(model_p, aes(x, predicted)) +
geom_smooth(method = "lm", se = TRUE, fullrange=TRUE) + xlab("Score") + ggtitle("Plot of Model of Income and Illiteracy Predicting Success") + ylab("Success") +
geom_point() + theme_minimal()
plot
dat$Illiteracy.t <- 3 - dat$Illiteracy.c
dat$literacy.t <- 3 - dat$Illiteracy.c
dat$Literacy.t <- 3 - dat$Illiteracy.c
# Multiple regression [Success ~ Income.c + Literacy.t]
modelB <- linReg(data = dat,
dep = 'Success', #outcome
covs = c('Income.C', 'Literacy.t'), #predictors
blocks = list(c('Income.C', 'Literacy.t')), #order matters here if separate blocks of variables are provided
modelTest = TRUE,
stdEst = TRUE,
ciStdEst = TRUE,
r2Adj = TRUE)
# Multiple regression [Success ~ Income.c + Literacy.t]
transform5 <- linReg(data = dat,
dep = 'Success', #outcome
covs = c('Income.c', 'Literacy.t'), #predictors
blocks = list(c('Income.c', 'Literacy.t')), #order matters here if separate blocks of variables are provided
modelTest = TRUE,
stdEst = TRUE,
ciStdEst = TRUE,
r2Adj = TRUE)
transform5
# plotting a multiple regression model based on:
# Model 5 Transform: Success.c ~ Income.c + Literacy.t [centered predictors]
# create predicted values from predictors and save in object
model5 <- lm(Success ~ Income.c + Literacy.t, data = dat)
summary(model5)
model_p <- ggpredict(model5, terms = c('Income.c', 'Literacy.t'), full.data = TRUE,  pretty = FALSE)
# plot predicted line
plot <- ggplot(model_p, aes(x, predicted)) +
geom_smooth(method = "lm", se = TRUE, fullrange=TRUE) + xlab("Score") + ggtitle("Plot of Model of Income and Literacy Predicting Success") + ylab("Success") +
geom_point() + theme_minimal()
plot
knitr::opts_chunk$set(echo = TRUE)
#Load libraries
library(psych)
library(car)
library(lsr)
library(jmv)
library(ggeffects)
library(ggplot2)
dat <- read.csv("https://www.dropbox.com/s/w3wl461s45t1yia/PSY.308c.DA3.csv?dl=1")
# Prerequisitites
# 1. Variables are measured on the continuous level
# Assumptions
# 1. Normal Distribution for X and Y (Product) [i.e. histogram, skew +-3, kurtosis +-10]
# Histogram for Income appears normal
# Histogram for Illitaracy appears unimodal and skewed positively
# Histogram for Safety appears normal
# Histogram for Success appears normal
# Skewness - ALL PASS
# Kurtosis - ALL PASS
# 2. Linear Relationship beween X and Y
# Visual inspection of scatterplot and prediction model line indicate a linear relationship
# 3. Homoscedasticity
# a. Visual inspection of scatterplots indicate:
# possible lower variance at lower end of Income
# possible lower variance at upper end of Illiteracy
# likely equal variance across Safety
# b. non-constant variance test - H0 = TRUE (PASS)
# 4. [Examine residuals (e = Y - Y~predicted~) to understand 2 and 3 mathematically]
# Descriptives [Assumption 1]
desc <- descriptives(data = dat,
vars = c('Income', 'Illiteracy', 'Safety', 'Success'),
hist = TRUE,
sd = TRUE,
range = TRUE,
skew = TRUE,
kurt = TRUE)
desc
# Scatterplots [Assumption 2 and 3a]
plot(dat$Income, dat$Success, abline(lm(dat$Success ~ dat$Income)))
plot(dat$Illiteracy, dat$Success, abline(lm(dat$Success ~ dat$Illiteracy)))
plot(dat$Safety, dat$Success, abline(lm(dat$Success ~ dat$Safety)))
# Homoscedasticity [Assumption 3b]
# non-constant variance Chi-squared test [Chi-squared (df) = ##.##, p = .###]
# H0 = homoscedastic - TRUE
# Ha = heteroscedastic
ncvTest(lm(Success ~ Income + Illiteracy + Safety, data = dat))
# Correlation
cortable <- corrMatrix(data = dat,
vars = c('Income', 'Illiteracy', 'Safety', 'Success'),
flag = TRUE)
cortable
# c = x - M
# Centering only quantitatively changes the intercept for regression equation
# Center Income, Illiteracy, Safety
dat$Income.c <- dat$Income - mean(dat$Income)
dat$Illiteracy.c <- dat$Illiteracy - mean(dat$Illiteracy)
dat$Safety.c <- dat$Safety - mean(dat$Safety)
View(dat)
# Simple regression
# R = correlation between observed scores and predicted scores
# R squared = percentage of variance explained
# t = Estimate / SE
# df = N - k - 1 [k is number of predictors]
# H0: B0 = 0; H0; R squared = 0
model1 <- linReg(data = dat,
dep = 'Success',
covs = c('Income.c'),
blocks = list('Income.c'),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
model1
model2 <- linReg(data = dat,
dep = 'Success',
covs = c('Illiteracy.c'),
blocks = list('Illiteracy.c'),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
model2
model3 <- linReg(data = dat,
dep = 'Success',
covs = c('Safety.c'),
blocks = list('Safety.c'),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
model3
# Model comparison
# H0 = delta of R squared = 0
compare5 <- linReg(data = dat,
dep = 'Success',
covs = c('Income.c', 'Illiteracy.c'),
blocks = list(
list('Income.c'),
list('Illiteracy.c')),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
compare5
# Model comparison
# H0 = delta of R squared = 0
compare6 <- linReg(data = dat,
dep = 'Success',
covs = c('Income.c', 'Safety.c'),
blocks = list(
list('Income.c'),
list('Safety.c')),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
compare6
# Model comparison
# H0 = delta of R squared = 0
# D1 is predicted difference between D1 (Graduated later) and reference group (Did not graduate) for a 1 unit change in Y (Success)
# D2 is predicted difference between D2 (Graduated normal) and reference group (did not graduate) for 1 unit change in Y (Success)
compare7 <- linReg(data = dat,
dep = 'Success',
covs = c('Income.c', 'D1', 'D2'),
blocks = list(
list('Income.c'),
list('D1', 'D2')),
modelTest = TRUE,
stdEst = TRUE,
ci = TRUE)
compare7
dat$Literacy.t <- 3 - dat$Illiteracy.c
# Multiple regression [Success ~ Income.c + Literacy.t]
# Y = B0 + B1*Income + B2*Literacy + residuals [B0 = 2.48, B1 = 12,600, B2 = 0.87]
# Accounting for error (Sum of Y - Y predicted / N - standard error in gray below):
#with average income and literacy, Y is 2.48 {low success}
#with average success and literacy, income is 12,600
#with average success and income, literacy is 0.87 {low literacy}
transform5 <- linReg(data = dat,
dep = 'Success', #outcome
covs = c('Income.c', 'Literacy.t'), #predictors
blocks = list(c('Income.c', 'Literacy.t')), #order matters here if separate blocks of variables are provided
modelTest = TRUE,
stdEst = TRUE,
ciStdEst = TRUE,
r2Adj = TRUE)
transform5
# plotting a multiple regression model based on:
# Model 5 Transform: Success.c ~ Income.c + Literacy.t [centered predictors]
# create predicted values from predictors and save in object
model5 <- lm(Success ~ Income.c + Literacy.t, data = dat)
summary(model5)
model_p <- ggpredict(model5, terms = c('Income.c', 'Literacy.t'), full.data = TRUE,  pretty = FALSE)
# plot predicted line
plot <- ggplot(model_p, aes(x, predicted)) +
geom_smooth(method = "lm", se = TRUE, fullrange=TRUE) + xlab("Score") + ggtitle("Plot of Model of Income and Literacy Predicting Success") + ylab("Success") +
geom_point() + theme_minimal()
plot
