---
title: "Binary Logistic Regression"
author: "Conway"
output:
  pdf_document: 
    latex_engine: xelatex
  html_document: default
---
  
  <!-- LEAVE THIS HERE, DO NOT PUT ANY CODE ABOVE IT -->
```{r, echo=FALSE, results=FALSE, message=FALSE, cache=FALSE}
library(knitr); opts_chunk$set(error=TRUE, cache=FALSE)
```

Prompt
----------
The data are based on a mock jury study conducted by Shari Diamond and Jonathan Casper. Subjects (N = 100) watched a videotaped sentencing phase trial in which the defendant had already been found guilty. The issue for the jurors to decide was whether the defendant deserved the death penalty. These data were collected "pre-deliberation"" (i.e., each juror was asked to provide his/her vote on the death penalty verdict, then the jurors met as a group to decide the overall jury verdict).The initial individual verdicts are given in this data set. Verdict is dummy coded: 0 = life sentence, 1 = death penalty.

**Load packages and import data**
```{r}

# Load packages
library(pacman)
p_load(psych, jmv, aod, QuantPsyc, ggeffects, ggplot2)

# Import data 
BL <- read.csv("https://www.dropbox.com/s/hd43va8a7hjfj27/Diamond.csv?dl=1")

```

**Descriptive statistics**
```{r}
# Descriptive statistics
# Including the binary outcome so we can see the frequencies (prints below Descriptives table)
# baseline classification success is equal to the reference frequency for Retention (No = 2)

desc <- descriptives(data = BL, 
                     vars = c('verdict', 'danger', 'rehab', 'punish', 'gendet', 'specdet', 'incap'), 
                     sd = TRUE, 
                     skew = TRUE, 
                     kurt = TRUE,
                     freq = TRUE,
                     hist = TRUE)
desc

```

Assumptions
1. Independence of Observations
2. Predictor Variables Normally Distributed
3. Multicollinearity not violated

**Correlations**
```{r}
# Correlation
cortable <- corrMatrix(data = BL, 
                       vars = c('verdict', 'danger', 'rehab', 'punish', 'gendet', 'specdet', 'incap'), 
                       flag = TRUE)
cortable
```

**Logistic Plots**
```{r}

p_load(popbio)
logi.hist.plot(BL$danger, BL$verdict, boxp=FALSE, type="hist", col="gray", xlabel = "danger")
logi.hist.plot(BL$rehab, BL$verdict, boxp=FALSE, type="hist", col="gray", xlabel = "rehab")
logi.hist.plot(BL$punish, BL$verdict, boxp=FALSE, type="hist", col="gray", xlabel = "punish")
logi.hist.plot(BL$gendet, BL$verdict, boxp=FALSE, type="hist", col="gray", xlabel = "gendet")
logi.hist.plot(BL$specdet, BL$verdict, boxp=FALSE, type="hist", col="gray", xlabel = "specdet")
logi.hist.plot(BL$incap, BL$verdict, boxp=FALSE, type="hist", col="gray", xlabel = "incap")

```

**BiLoRe Models**

```{r}

# Null model
# Null deviance = Chi squared for the model
# df = N - (# of predictors) - 1
model0 <- glm(BL$verdict ~ 1, family = binomial)
summary(model0)

print("Logit")
coef(model0)

model0.odds <- exp(coef(model0)) #converts coefficient to odds [P(outcome)/(1-P(outcome))]
print("Odds")
model0.odds


model0.probs <- model0.odds / (1 + model0.odds) #
print("Probabilities")
model0.probs


print("Columns = Observed, Rows = Predicted")
print("Null model") 
ClassLog(model0, BL$verdict) # classification success under the null model (baseline)
```

```{r}
# Model with predictors specific to the defendent.
# when odds ratio < 1 just flip (invert) the result(in relation to "no" instead of in relation to "yes")

# Deviance score is the chi-squared for this model
# AIC is used to compare non-nested models for fit (lower means better fit)
# top chi-squared indicates the change of chi-squared vs the null model (Deviance + chi squared)
# top df score indicates the change of df vs the null model
# df = N - (# of predictors) - 1

model1.jmv <- jmv::logRegBin(
  data = dat.subset,
  dep = Re,
  covs = vars(danger, specdet, incap, rehab, punish, gendet),
  blocks = list(
    list(
      'danger',
      'specdet',
      'incap')),
  refLevels = list(
    list(
      var = 'verdict',
      ref = '0')),
  modelTest = TRUE,
  OR = TRUE,
  class = TRUE,
  acc = TRUE,
  collin = TRUE)

model1.jmv
```

```{r}
# Model with predictors about the criminal justice system.

#Multicollinearity

#Tolerance = 1 - R squared --> for our purpose < .4 is bad
#VIF = 1/Tolerance 
#  Small VIF values indicates low correlation among variables under ideal conditions
#Multicollinearity occurs when two or more predictors in the model are correlated and provide redundant information about the response. Multicollinearity was measured by variance inflation factors (VIF) and tolerance. If VIF value exceeding 4.0, or by tol- erance less than 0.2 then there is a problem with multicollinearity (Hair et al., 2010).

model2.jmv <- jmv::logRegBin(
  data = BL,
  dep = verdict,
  covs = vars(danger, specdet, incap, rehab, punish, gendet),
  blocks = list(
    list(
      'rehab',
      'punish',
      'gendet')),
  refLevels = list(
    list(
      var = 'verdict',
      ref = '0')),
  modelTest = TRUE,
  OR = TRUE,
  class = TRUE,
  acc = TRUE,
  collin = TRUE)

model2.jmv

```

```{r}
# Model with all predictors

model3.jmv <- jmv::logRegBin(
  data = BL,
  dep = verdict,
  covs = vars(danger, specdet, incap, rehab, punish, gendet),
  blocks = list(
    list(
      'danger',
      'specdet',
      'incap',
      'rehab',
      'punish',
      'gendet')),
  refLevels = list(
    list(
      var = 'verdict',
      ref = '0')),
  modelTest = TRUE,
  OR = TRUE,
  class = TRUE,
  acc = TRUE,
  collin = TRUE)

model3.jmv
```

**Model Comparison**

```{r}
# Model1 vs. Model3
# This is a similar set up to multiple regression in terms of the code, so if you know you will be running both models, you can just use this code and have the model comparison stats as well. 

modelcomp.jmv <- jmv::logRegBin(
  data = BL,
  dep = verdict,
  covs = vars(danger, specdet, incap, rehab, punish, gendet),
  blocks = list(
    list(
      'danger',
      'specdet',
      'incap'),
    list(
      'rehab',
      'punish',
      'gendet')),
  refLevels = list(
    list(
      var = 'verdict',
      ref = '0')),
  modelTest = TRUE,
  OR = TRUE,
  class = TRUE,
  acc = TRUE,
  collin = TRUE)

modelcomp.jmv
```

**Center Predictors**
```{r}

BL$dangerC <- BL$danger - mean(BL$danger)
BL$rehabC <- BL$rehab - mean(BL$rehab)
BL$punishC <- BL$punish - mean(BL$punish)
BL$gendetC <- BL$gendet - mean(BL$gendet)
BL$specdetC <- BL$specdet - mean(BL$specdet)
BL$incapC <- BL$incap - mean(BL$incap)

```

**Re-run model with all predictors and run parsimonious model.** 
```{r}

#remove not significant predictors

finalmodel.jmv <- logRegBin(
  data = BL,
  dep = verdict,
  covs = vars(dangerC, specdetC, incapC, rehabC, punishC, gendetC),
  blocks = list(
    list(
      'dangerC', # significant predictors only
      'rehabC',
      'gendetC'),
    list(
      'specdetC', # full model
      'incapC',
      'punishC')),
  refLevels = list(
    list(
      var = 'verdict',
      ref = '0')),
  modelTest = TRUE,
  OR = TRUE,
  class = TRUE,
  acc = TRUE,
  collin = TRUE)

finalmodel.jmv
```

# Use regression equation to calculate predicted logit, odds, and probability 
```{r}
# Let D = danger, R = rehab, G = gendet
D = 10
R = 0
G = 10

predlogit <- -.096 + (.278*D) + (-.181*R) + (.188*G)
predodds <- exp(predlogit)
predprob <- predodds / (1 + predodds)

predlogit
predodds
predprob

```
