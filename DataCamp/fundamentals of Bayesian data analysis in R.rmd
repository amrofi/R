---
title: "Fundamentals of Bayesian Data Analysis in R"
author: "DataCamp - Rasmus Bååth"
date: "2/4/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(repos="https://CRAN.R-project.org")
```

## A first taste of Bayes

![](_images/1775.png)

![](_images/1776.png)

![](_images/1777.png)

## Let's try some Bayesian data analysis

![](_images/1778.png)

![](_images/1779.png)

![](_images/1780.png)

![](_images/1781.png)

![](_images/1782.png)

**Coin flips with prop_model**

The function `prop_model` has been loaded into your workspace. It implements a Bayesian model that assumes that:

- The `data` is a vector of successes and failures represented by `1`s and `0`s.
- There is an unknown underlying proportion of success.
- Prior to being updated with data any underlying proportion of success is equally likely.

Assume you just flipped a coin four times and the result was *heads*, *tails*, *tails*, *heads*. If you code *heads* as a success and *tails* as a failure then the following R codes runs *prop_model* with this data

```r
data <- c(1, 0, 0, 1)
prop_model(data)
```

```{r}
library(tidyverse)
library(ggridges)

prop_model <- function (data = c(), prior_prop = c(1, 1), n_draws = 10000, 
    show_plot = TRUE) 
{
    data <- as.logical(data)
    proportion_success <- c(0, seq(0, 1, length.out = 100), 1)
    data_indices <- round(seq(0, length(data), length.out = min(length(data) + 
        1, 20)))
    post_curves <- map_dfr(data_indices, function(i) {
        value <- ifelse(i == 0, "Prior", ifelse(data[i], "Success", 
            "Failure"))
        label <- paste0("n=", i)
        probability <- dbeta(proportion_success, prior_prop[1] + 
            sum(data[seq_len(i)]), prior_prop[2] + sum(!data[seq_len(i)]))
        probability <- probability/max(probability)
        tibble(value, label, proportion_success, probability)
    })
    post_curves$label <- fct_rev(factor(post_curves$label, levels = paste0("n=", 
        data_indices)))
    post_curves$value <- factor(post_curves$value, levels = c("Prior", 
        "Success", "Failure"))
    p <- ggplot(post_curves, aes(x = proportion_success, y = label, 
        height = probability, fill = value)) + geom_density_ridges(stat = "identity", 
        color = "white", alpha = 0.8, panel_scaling = TRUE, size = 1) + 
        scale_y_discrete("", expand = c(0.01, 0)) + scale_x_continuous("Underlying proportion of success") + 
        scale_fill_manual(values = hcl(120 * 2:0 + 15, 100, 65), 
            name = "", drop = FALSE, labels = c("Prior   ", "Success   ", 
                "Failure   ")) + theme_light(base_size = 18) + 
        theme(legend.position = "top")
    if (show_plot) {
        print(p)
    }
    invisible(rbeta(n_draws, prior_prop[1] + sum(data), prior_prop[2] + 
        sum(!data)))
}
```

```{r}
data <- c(1, 0, 0, 1)
prop_model(data)
```

The model knows it's not close to 0% or close to 100%, but believes it could be anything in between.

**Zombie drugs with prop_model**

If we really were interested in the underlying proportion of heads of this coin then `prop_model` isn't particularly useful. Since it assumes that any underlying proportion of success is equally likely prior to seeing any data it will take a lot of coin flipping to convince `prop_model` that the coin is fair. This model is more appropriate in a situation where we have little background knowledge about the underlying proportion of success.

```{r}
# Update the data and rerun prop_model
data = c(rep.int(0, 11), 1, 1)
prop_model(data)
```

It seems like it's not a perfect drug, but between 5% to 40% cured zombies is better than nothing!

## Samples and posterior summaries

![](_images/1783.png)

![](_images/1784.png)

![](_images/1785.png)

![](_images/1786.png)

![](_images/1787.png)

**Looking at samples from prop_model**

Here again is the `prop_model` function which has been given the data from our zombie experiment where two out of 13 zombies got cured. In addition to producing a plot, `prop_model` also returns a large random sample from the posterior over the underlying proportion of success.

```{r}
data = c(1, 0, 0, 1, 0, 0,
         0, 0, 0, 0, 0, 0, 0)
         
# Extract and explore the posterior
posterior <- prop_model(data)
head(posterior)

# Plot the histogram of the posterior
hist(posterior, breaks = 30, xlim = c(0, 1), col = "palegreen4")
```

Hey, that's a good looking plot!

**Summarizing the zombie drug experiment**

The point of working with samples from a probability distribution is that it makes it easy to calculate new measures of interest. The following tasks are about doing just this!

A *point estimate* is a single number used to summarize what's known about a parameter of interest. It can be seen as a "best guess" of the value of the parameter. A commonly used point estimate is the **median** of the posterior. It's the midpoint of the distribution, and it's equally probable for the parameter value to be larger than the median as it is to be smaller than it.

```{r}
# Calculate the median
median(posterior)
```

So, a best guess is that the drug would cure around 18% of all zombies. Another common summary is to report an interval that includes the parameter of interest with a certain probability. This is called a *credible interval* (CI). With a posterior represented as a vector of samples you can calculate a CI using the `quantile()` function.

```{r}
# Calculate the credible interval
quantile(posterior, c(0.05, 0.95))
```

According to the credible interval, there is a 90% probability that the proportion of zombies the drug would cure is between 6% and 38%. (Here we have to be careful to remember that the percentage of cured zombies and the percentage of probability are two different things.)

Now, there is a rival zombie laboratory that is also working on a drug. They claim that they are certain that their drug cures 7% of the zombies it's administered to. Can we calculate how probable it is that our drug is better? Yes, we can! But it's a two stage process.

```{r}
# Calculate the sum
sum(posterior > 0.07)

# Calculate the probability
sum(posterior > 0.07)/length(posterior)
```

It seems there is a large probability (93%) that our zombie drug is better!

## You've done some Bayesian data analysis!

![](_images/1788.png)

![](_images/1789.png)

## The parts needed for Bayesian inference

![](_images/1790.png)

![](_images/1791.png)

![](_images/1792.png)

**Take a generative model for a spin**

Below you have the R code that implements the generative model we just developed.

```{r}
# The generative zombie drug model

# Set parameters
prop_success <- 0.42
n_zombies <- 100

# Simulating data
data <- c()
for(zombie in 1:n_zombies) {
  data[zombie] <- runif(1, min = 0, max = 1) < prop_success
}

data <- as.numeric(data)
data

# Count cured
data <- sum(data)
data
```

Perfect! Some zombies got cured in this simulation, but far from all.

**Take the binomial distribution for a spin**

It turns out that the generative model you ran last exercise already has a name. It's called the **binomial process** or the **binomial distribution**. In R you can use the `rbinom` function to simulate data from a binomial distribution. The `rbinom` function takes three arguments:

- `n` The number of times you want to run the generative model
- `size` The number of trials. (For example, the number of zombies you're giving the drug.)
- `prob` The underlying proportion of success as a number between `0.0` and `1.0`.

```{r}
# Try out rbinom
rbinom(n = 1, size = 100, prob = 0.42)

# Change the parameters
rbinom(n = 200, size = 100, prob = 0.42)
```

Nice! That's a lot of simulated zombies right there.

## Using a generative model

![](_images/1793.png)

![](_images/1794.png)

![](_images/1795.png)

![](_images/1796.png)

**How many visitors could your site get (1)?**

To get more visitors to your website you are considering paying for an ad to be shown 100 times on a popular social media site. According to the social media site, their ads get clicked on 10% of the time.

```{r}
# Fill in the parameters
n_samples <- 100000
n_ads_shown <- 100
proportion_clicks <- 0.10
n_visitors <- rbinom(n_samples, size = n_ads_shown, 
                     prob = proportion_clicks)

# Visualize n_visitors
hist(n_visitors, breaks = 25, col = "palegreen4")
```

## Representing uncertainty with priors

![](_images/1797.png)

![](_images/1798.png)

**Adding a prior to the model**

You're not so sure that your ad will get clicked on exactly 10% of the time. Instead of assigning `proportion_clicks` a single value you are now going to assign it a large number of values drawn from a probability distribution.

For now, we are going to assume that it's equally likely that `proportion_clicks` could be as low as 0% or as high as 20%. 

```{r}
n_samples <- 100000
n_ads_shown <- 100

# Update proportion_clicks
proportion_clicks <- runif(n = n_samples, min = 0.0, max = 0.2)

n_visitors <- rbinom(n = n_samples, size = n_ads_shown, prob = proportion_clicks)
```

Because the `rbinom` function is vectorized the first value of `proportion_clicks` is used to sample the first value in `n_visitors`, the second value in `proportion_clicks` is used for the second in `n_visitors`, and so on. The result is that the samples in `n_visitors` now also incorporate the uncertainty in what the underlying proportion of clicks could be.

```{r}
# Visualize proportion clicks
hist(proportion_clicks, col = "blue")
```

You shouldn't be surprised to see that the uncertainty over `proportion_clicks` is just as you specified it to be: Uniform between 0.0 and 0.2 (except for some small variations in the height of the bars because we took a random sample using `runif`).

```{r}
# Visualize n_visitors
hist(n_visitors, col = "palegreen4")
```

Uncertainty changed the distribution. We went from a random distribution of about 90% to, with added uncertainty of 0 to 20%, 70% likelihood that someone will click on an ad.

## Bayesian models and conditioning

![](_images/1799.png)

![](_images/1800.png)

![](_images/1801.png)

![](_images/1802.png)

![](_images/1803.png)

![](_images/1804.png)

![](_images/1805.png)

**Update a Bayesian model with data**

You ran your ad campaign, and 13 people clicked and visited your site when the ad was shown a 100 times. You would now like to use this new information to update the Bayesian model.

```{r}
# Create the prior data frame
prior <- data.frame(proportion_clicks, n_visitors)

# Examine the prior data frame
head(prior)
```

The reason we've called it prior is because it represents the uncertainty before (that is, prior to) having included the information in the data. Let's do that now!

`prior$n_visitors` represented the uncertainty over how many visitors you would get because of the ad campaign. But now you know you got exactly 13 visitors.

```{r}
# Create the posterior data frame
posterior <- prior[prior$n_visitors == 13, ]

# Visualize posterior proportion clicks
hist(posterior$proportion_clicks, col = "palegreen4")
```

**How many visitors could your site get (3)?**

In the last exercise, you updated the probability distribution over the underlying proportions of clicks (`proportion_clicks`) using new data. Now we want to use this updated `proportion_clicks` to predict how many visitors we would get if we reran the ad campaign.

The result from the last exercise is still in the data frame `posterior`, but if you look at `posterior$n_visits` you'll see it's just `13` repeated over and over again. This makes sense as `posterior` represents what the model knew about the outcome of the last ad campaign after having seen the data.

```{r}
# Assign posterior to a new variable called prior
prior <- posterior

# Take a look at the first rows in prior
head(prior)

# Replace prior$n_visitors with a new sample and visualize the result
n_samples <-  nrow(prior)
n_ads_shown <- 100
prior$n_visitors <- rbinom(n_samples, size = n_ads_shown,
                           prob = prior$proportion_clicks)
hist(prior$n_visitors, col = "palegreen4")

# Calculate the probability that you will get 5 or more visitors
sum(prior$n_visitors >= 5)/length(prior$n_visitors)
```

It's pretty probable that you'll get more than 5 visitors.

## What have we done?

**Joint Probability Distribution**

![](_images/1806.png)

![](_images/1807.png)

**Chapter 4: Computational Methods**

![](_images/1808.png)

## Four good things with Bayes













