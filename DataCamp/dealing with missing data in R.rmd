---
title: "Dealing With Missing Data in R"
author: "Datacamp - Nicholas Tierney"
date: "1/5/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(repos="https://CRAN.R-project.org")
```

## Introduction to missing data

![](_images/1593.png)

![](_images/1594.png)

![](_images/1595.png)

![](_images/1596.png)

![](_images/1597.png)

![](_images/1598.png)

![](_images/1599.png)

**Using and finding missing values**

When working with missing data, there are a couple of commands that you should be familiar with - firstly, you should be able to identify if there are **any** missing values, and where these **are**.

Using the `any_na()` and `are_na()` tools, identify which values are missing.

```{r}
library(tidyverse)
library(naniar)

# Create x, a vector, with values NA, NaN, Inf, ".", and "missing"
x <- c(NA, NaN, Inf, ".", "missing")

# Use any_na() and are_na() on to explore the missings
any_na(x)
are_na(x)
```

Well done! You've now learned how to use `any_na()` and `are_na()` to identify missing values.

**How many missing values are there?**

One of the first things that you will want to check with a new dataset is if there are any missing missing values, and how many there are.

You could use `are_na()` to and count up the missing values, but **the most efficient way** to count missings is to use the `n_miss()` function. This will tell you the **total number of missing values** in the data.

You can then find the percent of missing values in the data with the `pct_miss` function. This will tell you the **percentage of missing values** in the data.

You can also find the complement to these - how many complete values there are - using `n_complete` and `pct_complete`.

```
# Use n_miss() to count the total number of missing values in dat_hw
n_miss(dat_hw)
```
```
[1] 30
```
```
# Use n_miss() on dat_hw$weight to count the total number of missing values
n_miss(dat_hw$weight)
```
```
[1] 15
```
```
# Use n_complete() on dat_hw to count the total number of complete values
n_complete(dat_hw)
```
```
[1] 170
```
```
# Use n_complete() on dat_hw$weight to count the total number of complete values
n_complete(dat_hw$weight)
```
```
[1] 85
```
```
# Use prop_miss() and prop_complete on dat_hw to count the total number of missing values in each of the variables
prop_miss(dat_hw)
prop_complete(dat_hw)
```
```
[1] 0.15
```

Congratulations! You've learned how to count the number and proportion of missing values using `n_miss()`, `prop_miss()`, `n_complete()`, and `prop_complete()`

## Why care about missing values?

![](_images/1600.png)

![](_images/1601.png)

![](_images/1602.png)

![](_images/1603.png)

![](_images/1604.png)

![](_images/1605.png)

![](_images/1606.png)

**Summarizing missingness**

Now that you understand the behavior of missing values in R, and how to count them, let's scale up our summaries for cases (rows) and variables, using `miss_var_summary()` and `miss_case_summary()`, and also explore how they can be applied for groups in a dataframe, using the `group_by` function from `dplyr`.

```{r}
# Summarize missingness in each variable of the `airquality` dataset
miss_var_summary(airquality)

# Summarize missingness in each case of the `airquality` dataset
miss_case_summary(airquality)

# Return the summary of missingness in each variable, 
# grouped by Month, in the `airquality` dataset
airquality %>% group_by(Month) %>% miss_var_summary()

# Return the summary of missingness in each case, 
# grouped by Month, in the `airquality` dataset
airquality %>% group_by(Month) %>% miss_case_summary()
```

Hooray! You now know how to summarize missingness for variables and cases for each groups!

**Tabulating Missingness**

The summaries of missingness we just calculated give us the number and percentage of missing observations for the cases and variables.

Another way to summarize missingness is by tabulating the number of times that there are 0, 1, 2, 3, missings in a variable, or in a case.

In this exercise we are going to tabulate the number of missings in each case and variable using `miss_var_table()` and `miss_case_table()`, and also combine these summaries with the the `group_by` operator from `dplyr`. to explore the summaries over a grouping variable in the dataset.

```{r}
# Tabulate missingness in each variable and case of the `airquality` dataset
miss_var_table(airquality)
miss_case_table(airquality)

# Tabulate the missingness in each variable, grouped by Month, in the `airquality` dataset
airquality %>% group_by(Month) %>% miss_var_table()

# Tabulate of missingness in each case, grouped by Month, in the `airquality` dataset
airquality %>% group_by(Month) %>% miss_case_table()
```

Fantastic! You have know learnt how to tabulate and summarize missingness for each variable and cases, and to get summaries for each of the groups.

**Other summaries of missingness**

Some summaries of missingness are particularly useful for different types of data. For example, `miss_var_span()` and `miss_var_run()`.

- `miss_var_span()` calculates the number of missing values in a specified variable for a repeating span. This is really useful in time series data, to look for weekly (7 day) patterns of missingness.

- `miss_var_run()` calculates the number of "runs" or "streaks" of missingness. This is useful to find unusual patterns of missingness, for example, you might find a repeating pattern of 5 complete and 5 missings.

Both `miss_var_span()` and `miss_var_run()` work with the `group_by` operator from `dplyr`.

```{r}
# Calculate the summaries for each run of missingness for the variable, hourly_counts
miss_var_run(pedestrian, var = hourly_counts)

# Calculate the summaries for each span of missingness, 
# for a span of 4000, for the variable hourly_counts
miss_var_span(pedestrian, var = hourly_counts, span_every = 4000)

# For each `month` variable, calculate the run of missingness for hourly_counts
pedestrian %>% group_by(month) %>% miss_var_run(var = hourly_counts)

# For each `month` variable, calculate the span of missingness 
# of a span of 2000, for the variable hourly_counts
pedestrian %>% group_by(month) %>% miss_var_span(var = hourly_counts, span_every = 2000)
```

Wonderful! You have now learnt how to summarize missingness over repeating spans, and find runs of missingness!

## How do we visualize missing values?

![](_images/1607.png)

![](_images/1608.png)

![](_images/1609.png)

![](_images/1610.png)

![](_images/1611.png)

![](_images/1612.png)

![](_images/1613.png)

![](_images/1614.png)

- does not support faceting

![](_images/1615.png)

- supports faceting

**Your first missing data visualizations**

It can be difficult to get a handle on where the missing values are in your data, and here is where visualization can really help.

The function `vis_miss()` creates an overview visualization of the missingness in the data. It also has options to cluster rows based on missingness, using `cluster = TRUE`; as well as options for sorting the columns, from most missing to least missing (`sort_miss = TRUE`).

```{r}
# Visualize all of the missingness in the `riskfactors`  dataset
vis_miss(riskfactors)

# Visualize and cluster all of the missingness in the `riskfactors` dataset
vis_miss(riskfactors, cluster = TRUE)

# Visualize and sort the columns by missingness in the `riskfactors` dataset
vis_miss(riskfactors, sort_miss = TRUE)
```

Excellent! You can now produce quick visual summaries of all missingness in the data using `vis_miss`!

**Visualizing missing cases and variables**

To get a clear picture of the missingness across variables and cases, use `gg_miss_var()` and `gg_miss_case()`. These are the visual counterpart to `miss_var_summary()` and `miss_case_summary()`.

These can be split up into multiple plots with one for each category by choosing a variable to facet by.

```{r}
# Visualize the number of missings in cases using `gg_miss_case()`
gg_miss_case(riskfactors)

# Explore the number of missings in cases using `gg_miss_case()` 
# and facet by the variable `education`
gg_miss_case(riskfactors, facet = education)

# Visualize the number of missings in variables using `gg_miss_var()`
gg_miss_var(riskfactors)

# Explore the number of missings in variables using `gg_miss_var()` 
# and facet by the variable `education`
gg_miss_var(riskfactors, facet = education)
```

Wahoo! You can now visualize missingness in a dataset for variables and cases, and explore how other variables interact with missingness.

**Visualizing missingness patterns**

Let's practice a few different ways to visualize patterns of missingness using:

- `gg_miss_upset()` to give an overall pattern of missingness.
- `gg_miss_fct()` for a dataset that has a factor of interest: marriage.
- and `gg_miss_span()` to explore the missingness in a time series dataset.

What do you notice with the missingness and the faceting in the data?

```{r}
# Using the airquality dataset, explore the missingness pattern using gg_miss_upset()
gg_miss_upset(airquality)

# With the riskfactors dataset, explore how the missingness changes across the marital variable using gg_miss_fct()
gg_miss_fct(x = riskfactors, fct = marital)

# Using the pedestrian dataset, explore how the missingness of hourly_counts changes over a span of 3000 
gg_miss_span(pedestrian, var = hourly_counts, span_every = 3000)

# Using the pedestrian dataset, explore the impact of month by faceting by month
# and explore how missingness changes for a span of 1000
gg_miss_span(pedestrian, var = hourly_counts, span_every = 1000, facet = month)
```

Splendid! You can now visualize different missingness patterns for different kinds of data

## Searching for and replacing missing values

![](_images/1616.png)

![](_images/1617.png)

![](_images/1618.png)

![](_images/1619.png)

![](_images/1620.png)

![](_images/1621.png)

**Using miss_scan_count**

You have a dataset with missing values coded as `"N/A"`, `"missing"`, and `"na"`. But before we go ahead and start replacing these with `NA`, we should get an idea of how big the problem is.

Use `miss_scan_count` to count the possible missings in the dataset, `pacman`, a dataset of pacman scores, containing three columns:

- `year`: the year that person made that score.
- `initial`: the initials of the person.
- `score`: the scores of that person.

```
# Explore the strange missing values "N/A"
miss_scan_count(data = pacman, search = list("N/A"))
```
```
# A tibble: 6 x 2
  Variable     n
  <chr>    <int>
1 year         0
2 month        0
3 day          0
4 initial      0
5 score      100
6 country      0
```
```
# Explore the strange missing values "missing"
miss_scan_count(data = pacman, search = list("missing"))
```
```
# A tibble: 6 x 2
  Variable     n
  <chr>    <int>
1 year        93
2 month       93
3 day         93
4 initial      0
5 score        0
6 country      0
```
```
# Explore the strange missing values "na"
miss_scan_count(data = pacman, search = list("na"))
```
```
# A tibble: 6 x 2
  Variable     n
  <chr>    <int>
1 year       100
2 month      100
3 day        100
4 initial      0
5 score        0
6 country      0
```
```
# Explore the strange missing values " " (a single space)
miss_scan_count(data = pacman, search = list(" "))
```
```
# A tibble: 6 x 2
  Variable     n
  <chr>    <int>
1 year         0
2 month        0
3 day          0
4 initial      0
5 score        0
6 country    100
```
```
# Explore all of the strange missing values, "N/A", "missing", "na", " "
miss_scan_count(data = pacman, search = list("N/A", "missing","na", " "))
```
```
# A tibble: 6 x 2
  Variable     n
  <chr>    <int>
1 year       193
2 month      193
3 day        193
4 initial      0
5 score      100
6 country    100
```

Fantastic! You've learned how to search for and count strange missing values

**Using replace_with_na**

Following on from the previous dataset, we now know that we have a few strange missing values.

Now, we are going to do something about it, and replace these values with missings (e.g. `NA`) using the function `replace_with_na()`.

```
# Print the top of the pacman data using `head()`
head(pacman)
```
```
# A tibble: 6 x 6
  year  month day   initial score   country
  <chr> <chr> <chr> <chr>   <chr>   <chr>  
1 2007  10    27    LEX     2065812 "CA"   
2 1995  8     23    PNY     1163465 "JP"   
3 1980  2     8     MBJ     175380  " "    
4 1982  5     9     QRC     2025632 "ES"   
5 na    na    na    YPZ     925357  "NZ"   
6 2013  11    15    RVJ     319733  "AU" 
```
```
# Replace the strange missing values "N/A", "na", and 
# "missing" with `NA` for the variables, year, and score
pacman_clean <- replace_with_na(pacman, replace = list(year = c("N/A", "na", "missing"),
                                score = c("N/A", "na", "missing")))
                                        
# Test if `pacman_clean` still has these values in it?
miss_scan_count(pacman_clean, search = list("N/A", "na", "missing"))
```
```
# A tibble: 6 x 2
  Variable     n
  <chr>    <int>
1 year         0
2 month      193
3 day        193
4 initial      0
5 score        0
6 country      0
```

You are doing great! You've now learned how to search for, replace, and confirm strange missing values in a dataset!

**Using replace_with_na scoped variants**

To reduce code repetition when replacing values with `NA`, use the "scoped variants" of `replace_with_na()`:

- `replace_with_na_at()`
- `replace_with_na_if()`
- `replace_with_na_all()`

The syntax of replacement looks like this:

```
~.x == "N/A"
```

This replaces all cases that are equal to "N/A".

```
~.x %in% c("N/A", "missing", "na", " ")
```

Replaces all cases that have `"N/A"`, `"missing"`, `"na"`, or `" "`

```
# Use `replace_with_na_at()` to replace with NA
replace_with_na_at(pacman,
                   .vars = c("year", "month", "day"), 
                   ~.x %in% c("N/A", "missing", "na", " "))
```
```
# A tibble: 2,000 x 6
   year  month day   initial score   country
   <chr> <chr> <chr> <chr>   <chr>   <chr>  
 1 2007  10    27    LEX     2065812 "CA"   
 2 1995  8     23    PNY     1163465 "JP"   
 3 1980  2     8     MBJ     175380  " "    
 4 1982  5     9     QRC     2025632 "ES"   
 5 <NA>  <NA>  <NA>  YPZ     925357  "NZ"   
 6 2013  11    15    RVJ     319733  "AU"   
 7 2003  12    4     VKD     3322668 "US"   
 8 2016  9     9     ZIS     2137806 "CN"   
 9 2013  3     20    IYD     3059716 "CN"   
10 1993  5     19    CHQ     231892  "AU"   
# ... with 1,990 more rows
```
```
# Use `replace_with_na_if()` to replace with NA the character values using `is.character`
replace_with_na_if(pacman,
                   .predicate = is.character, 
                   ~.x %in% c("N/A", "missing", "na", " "))
```
```
# A tibble: 2,000 x 6
   year  month day   initial score   country
   <chr> <chr> <chr> <chr>   <chr>   <chr>  
 1 2007  10    27    LEX     2065812 CA     
 2 1995  8     23    PNY     1163465 JP     
 3 1980  2     8     MBJ     175380  <NA>   
 4 1982  5     9     QRC     2025632 ES     
 5 <NA>  <NA>  <NA>  YPZ     925357  NZ     
 6 2013  11    15    RVJ     319733  AU     
 7 2003  12    4     VKD     3322668 US     
 8 2016  9     9     ZIS     2137806 CN     
 9 2013  3     20    IYD     3059716 CN     
10 1993  5     19    CHQ     231892  AU     
# ... with 1,990 more rows
```
```
# Use `replace_with_na_all()` to replace with NA
replace_with_na_all(pacman, ~.x %in% c("N/A", "missing", "na", " "))
```
```
# A tibble: 2,000 x 6
   year  month day   initial score   country
   <chr> <chr> <chr> <chr>   <chr>   <chr>  
 1 2007  10    27    LEX     2065812 CA     
 2 1995  8     23    PNY     1163465 JP     
 3 1980  2     8     MBJ     175380  <NA>   
 4 1982  5     9     QRC     2025632 ES     
 5 <NA>  <NA>  <NA>  YPZ     925357  NZ     
 6 2013  11    15    RVJ     319733  AU     
 7 2003  12    4     VKD     3322668 US     
 8 2016  9     9     ZIS     2137806 CN     
 9 2013  3     20    IYD     3059716 CN     
10 1993  5     19    CHQ     231892  AU     
# ... with 1,990 more rows
```

Super! Now you know how to use the powerful scoped variants of `replace_with_na()` to replace values with `NA`.

## Filling down missing values

![](_images/1622.png)

![](_images/1623.png)

![](_images/1624.png)

![](_images/1625.png)

![](_images/1626.png)

- **l**ast **o**bservation **c**arried **f**orward
- *Warning*: this method is only useful in this specific type of case

**Fix implicit missings using complete()**

We are going to explore a new dataset, `frogger`.

This dataset contains 4 scores per player recorded at different times: `morning`, `afternoon`, `evening`, and `late_night`.

Every player should have played 4 games, one at each of these times, but it looks like not every player completed all of these games.

Use the `complete()` function to make these **implicit** missing values **explicit**

```
# Print the frogger data to have a look at it
frogger
```
```
    name       time  value
1  jesse    morning   6678
2  jesse  afternoon 800060
3  jesse    evening 475528
4  jesse late_night 143533
5   andy    morning 425115
6   andy  afternoon 587468
7   andy late_night 111000
8    nic  afternoon 588532
9    nic late_night 915533
10   dan    morning 388148
11   dan    evening 180912
12  alex    morning 552670
13  alex  afternoon  98355
14  alex    evening 266055
15  alex late_night 121056
```
```
# Use `complete()` on the `time` and `name` variables to  
# make implicit missing values explicit
frogger_tidy <- frogger %>% complete(time, name)
```
```
# A tibble: 20 x 3
   time       name   value
   <fct>      <fct>  <int>
 1 afternoon  alex   98355
 2 afternoon  andy  587468
 3 afternoon  dan       NA
 4 afternoon  jesse 800060
 5 afternoon  nic   588532
 6 evening    alex  266055
 7 evening    andy      NA
 8 evening    dan   180912
 9 evening    jesse 475528
10 evening    nic       NA
11 late_night alex  121056
12 late_night andy  111000
13 late_night dan       NA
14 late_night jesse 143533
15 late_night nic   915533
16 morning    alex  552670
17 morning    andy  425115
18 morning    dan   388148
19 morning    jesse   6678
20 morning    nic       NA
```

Excellent! The `complete()` function converts implicitly missing values into explicitly missing values.

**Fix explicit missings using fill()**

One type of missing value that can be obvious to deal with is where the first entry of a group is given, but subsequent entries are marked `NA`.

These missing values often result from empty values in spreadsheets to avoid entering multiple names multiple times; as well as for "human readability".

This type of problem can be solved by using the `fill()` function from the `tidyr` package.

```
# Print the frogger data to have a look at it
frogger
```
```
# A tibble: 15 x 4
   name  time        value  year
   <chr> <chr>       <int> <dbl>
 1 jesse morning      6678  1981
 2 <NA>  afternoon  800060    NA
 3 <NA>  evening    475528    NA
 4 <NA>  late_night 143533    NA
 5 andy  morning    425115    NA
 6 <NA>  afternoon  587468    NA
 7 <NA>  late_night 111000    NA
 8 nic   afternoon  588532    NA
 9 <NA>  late_night 915533    NA
10 dan   morning    388148  1988
11 <NA>  evening    180912    NA
12 alex  morning    552670    NA
13 <NA>  afternoon   98355    NA
14 <NA>  evening    266055    NA
15 <NA>  late_night 121056    NA
```
```
# Use `fill()` to fill down the name variable in the frogger dataset
frogger %>% fill(name)
```
```
# A tibble: 15 x 4
   name  time        value  year
   <chr> <chr>       <int> <dbl>
 1 jesse morning      6678  1981
 2 jesse afternoon  800060    NA
 3 jesse evening    475528    NA
 4 jesse late_night 143533    NA
 5 andy  morning    425115    NA
 6 andy  afternoon  587468    NA
 7 andy  late_night 111000    NA
 8 nic   afternoon  588532    NA
 9 nic   late_night 915533    NA
10 dan   morning    388148  1988
11 dan   evening    180912    NA
12 alex  morning    552670    NA
13 alex  afternoon   98355    NA
14 alex  evening    266055    NA
15 alex  late_night 121056    NA
```

Excellent! The fill function makes it easy to fill down observations.

**Using complete() and fill() together**

Now let's put it together!

Use `complete()` and `fill()` together to fix explicit and implicitly missing values in the `frogger` dataset.

```
# Print the frogger data to have a look at it
frogger
```
```
# A tibble: 15 x 4
   name  time        value  year
   <chr> <chr>       <int> <dbl>
 1 jesse morning      6678  1981
 2 <NA>  afternoon  800060    NA
 3 <NA>  evening    475528    NA
 4 <NA>  late_night 143533    NA
 5 andy  morning    425115    NA
 6 <NA>  afternoon  587468    NA
 7 <NA>  late_night 111000    NA
 8 nic   afternoon  588532    NA
 9 <NA>  late_night 915533    NA
10 dan   morning    388148  1988
11 <NA>  evening    180912    NA
12 alex  morning    552670    NA
13 <NA>  afternoon   98355    NA
14 <NA>  evening    266055    NA
15 <NA>  late_night 121056    NA
```
```
# Correctly fill() and complete() missing values so that our dataset becomes sensible
frogger %>%
  fill(name) %>%
  complete(name, time)
```
```
# A tibble: 20 x 4
   name  time        value  year
   <chr> <chr>       <int> <dbl>
 1 alex  afternoon   98355    NA
 2 alex  evening    266055    NA
 3 alex  late_night 121056    NA
 4 alex  morning    552670    NA
 5 andy  afternoon  587468    NA
 6 andy  evening        NA    NA
 7 andy  late_night 111000    NA
 8 andy  morning    425115    NA
 9 dan   afternoon      NA    NA
10 dan   evening    180912    NA
11 dan   late_night     NA    NA
12 dan   morning    388148  1988
13 jesse afternoon  800060    NA
14 jesse evening    475528    NA
15 jesse late_night 143533    NA
16 jesse morning      6678  1981
17 nic   afternoon  588532    NA
18 nic   evening        NA    NA
19 nic   late_night 915533    NA
20 nic   morning        NA    NA
```

Faaaantastic! You correctly used the fill and complete functions in the right order to create a sensible dataset.

## Missing Data dependence

![](_images/1627.png)

![](_images/1628.png)

![](_images/1629.png)

![](_images/1630.png)

**Edit**: Missingness depends on data observed, but not data *un*observed

![](_images/1631.png)

![](_images/1632.png)

![](_images/1633.png)

![](_images/1634.png)

**Exploring missingness dependence**

To learn about the structure of the missingness in data, you can explore how sorting changes how missingness is presented.

For the `oceanbuoys` dataset, explore the missingness with `vis_miss()`, and then arrange by a few different variables

This is not a definitive process, but it will get you started to ask the right questions of your data. We explore more powerful techniques in the next chapter.

```{r}
# Arrange by year
oceanbuoys %>% arrange(year) %>% vis_miss()

# Arrange by latitude
oceanbuoys %>% arrange(latitude) %>% vis_miss()

# Arrange by wind_ew (wind east west)
oceanbuoys %>% arrange(wind_ew) %>% vis_miss()
```

Wahoo! You did it. We have some ideas for how to explore missingness in the data, but we are going to explore how to better explain and explore missingness in the next chapter.












